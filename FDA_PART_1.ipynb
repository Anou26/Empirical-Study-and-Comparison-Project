{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FDA_PART-1",
      "provenance": [],
      "authorship_tag": "ABX9TyMQxuc+HaHz/TAQ6PnTiuk4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anou26/Empirical-Study-and-Comparison-Project/blob/main/FDA_PART_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "9VqDyB6Y15Cx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6_lBTbI1wVg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import percentile\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "import re # for regular expressions\n",
        "import pandas as pd \n",
        "pd.set_option(\"display.max_colwidth\", 200) \n",
        "import string\n",
        "import branca.colormap as cm\n",
        "import requests\n",
        "import folium\n",
        "from folium import plugins\n",
        "from folium.plugins import HeatMap\n",
        "import nltk # for text manipulation\n",
        "from nltk.stem.porter import *\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag, ne_chunk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as sid\n",
        "from wordcloud import WordCloud\n",
        "from tqdm import tqdm, notebook\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from tqdm import tqdm\n",
        "from gensim.models.doc2vec import LabeledSentence\n",
        "import gensim\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy import stats \n",
        "from sklearn import metrics \n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error, make_scorer,classification_report,confusion_matrix,accuracy_score,roc_auc_score,roc_curve\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting and Reviewing our dataset"
      ],
      "metadata": {
        "id": "_rKoVO8W2B3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"https://raw.githubusercontent.com/gabrielpreda/covid-19-tweets/master/covid19_tweets.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "o36tDvmr2FjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "BLOBKMiL2K0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "QzK9FX0A2MAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "4UqjzTYP2OwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 12220 unique locations from where the tweets came.\n",
        "df['user_location'].value_counts()"
      ],
      "metadata": {
        "id": "m2oLCnXS2Rku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking for Null Values"
      ],
      "metadata": {
        "id": "ecOzPUvQ2ORf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = pd.DataFrame()\n",
        "missing_values['column'] = df.columns\n",
        "\n",
        "missing_values['percent'] = [round(100* df[col].isnull().sum() / len(df), 2) for col in df.columns]\n",
        "missing_values = missing_values.sort_values('percent')\n",
        "missing_values = missing_values[missing_values['percent']>0]\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.set(style='whitegrid', color_codes=True)\n",
        "splot=sns.barplot(x='column', y='percent', data=missing_values)\n",
        "for p in splot.patches:\n",
        "    splot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center',\n",
        "                   va = 'center', xytext = (0, 9), textcoords = 'offset points')\n",
        "plt.xlabel(\"Column_Name\", size=14, weight=\"bold\")\n",
        "plt.ylabel(\"Percentage\", size=14, weight=\"bold\")\n",
        "plt.title(\"Percentage of missing values in column\",fontweight=\"bold\",size=17)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QEzM_y5t2Ttu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HeatMap for missing values"
      ],
      "metadata": {
        "id": "KIZHlbpM2ISH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(17, 5))\n",
        "sns.heatmap(df.isnull(), cbar=True, yticklabels=False)\n",
        "plt.xlabel(\"Column_Name\", size=14, weight=\"bold\")\n",
        "plt.title(\"Places of missing values in column\",fontweight=\"bold\",size=17)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f3blVF_r2eZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "WspB2eVD2lev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df.corr())"
      ],
      "metadata": {
        "id": "bvUDa4FP2m0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unique values in each feature column"
      ],
      "metadata": {
        "id": "lm1OYOZs2hRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_df = pd.DataFrame()\n",
        "unique_df['Features'] = df.columns\n",
        "unique=[]\n",
        "for i in df.columns:\n",
        "    unique.append(df[i].nunique())\n",
        "unique_df['Uniques'] = unique\n",
        "\n",
        "f, ax = plt.subplots(1,1, figsize=(15,7))\n",
        "\n",
        "splot = sns.barplot(x=unique_df['Features'], y=unique_df['Uniques'], alpha=0.8)\n",
        "for p in splot.patches:\n",
        "    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center',\n",
        "                   va = 'center', xytext = (0, 9), textcoords = 'offset points')\n",
        "plt.title('Bar plot for number of unique values in each column',weight='bold', size=15)\n",
        "plt.ylabel('#Unique values', size=12, weight='bold')\n",
        "plt.xlabel('Features', size=12, weight='bold')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_00KgFDh2o__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot of top 15 locations of tweets"
      ],
      "metadata": {
        "id": "FgRglgat2wa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loc_analysis = pd.DataFrame(df['user_location'].value_counts().sort_values(ascending=False))\n",
        "loc_analysis = loc_analysis.rename(columns={'user_location':'count'})"
      ],
      "metadata": {
        "id": "ksmiD0gN20tN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "d0JorAO223Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "   \"values\": loc_analysis['count'][:15],\n",
        "   \"labels\": loc_analysis.index[:15],\n",
        "   \"domain\": {\"column\": 0},\n",
        "   \"name\": \"Location Name\",\n",
        "   \"hoverinfo\":\"label+percent+name\",\n",
        "   \"hole\": .4,\n",
        "   \"type\": \"pie\"\n",
        "}\n",
        "layout = go.Layout(title=\"<b>Ratio on Location</b>\", legend=dict(x=0.1, y=1.1, orientation=\"h\"))\n",
        "\n",
        "data = [data]\n",
        "fig = go.Figure(data = data, layout = layout)\n",
        "fig.update_layout(title_x=0.5)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "-e1zCFb_25WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "Wtjb0LWS28fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write function for removing @user\n",
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i,'',input_txt)\n",
        "    return input_txt\n",
        "# create new column with removed @user\n",
        "df['clean_text'] = np.vectorize(remove_pattern)(df['text'], '@[\\w]*')\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "AhJWKF0l27Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove http and urls from tweets"
      ],
      "metadata": {
        "id": "PBKEamSE3Dco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "df['clean_text'] = df['clean_text'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "jc99kDok3CCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove special characters, numbers, punctuations\n",
        "df['clean_text'] = df['clean_text'].str.replace('[^a-zA-Z#]+',' ')"
      ],
      "metadata": {
        "id": "Qzpof4KW3Nlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "2wLaL9WQ3Pka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove short words\n",
        "df['clean_text'] = df['clean_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 2]))\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "FS-6u0_W3Rpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create new variable tokenized tweet \n",
        "tokenized_tweet = df['clean_text'].apply(lambda x: x.split())\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "eRnsJkZ73Tlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "# apply stemmer for tokenized_tweet\n",
        "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x])\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "qN7XSUVi3Vs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# join tokens into one sentence\n",
        "for i in range(len(tokenized_tweet)):\n",
        "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
        "# change df['clean_text'] to tokenized_tweet"
      ],
      "metadata": {
        "id": "MqR9W5SF3Xoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text']  = tokenized_tweet\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "dihclsf03Z9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "YdgVGno63bu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create text from all tweets\n",
        "all_words = ' '.join([text for text in df['clean_text']])\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RGRVX3GV3hgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting features from cleaned tweets"
      ],
      "metadata": {
        "id": "HXnIDBSj3jz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "8Ygvk2lu3iFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')"
      ],
      "metadata": {
        "id": "_6m8SbSY3qVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text'].apply(lambda x: [item for item in x if item not in stop])"
      ],
      "metadata": {
        "id": "Y0mKTlgE3smx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "6rt7Gy8D3ud5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check and calculate the sentiments of tweets"
      ],
      "metadata": {
        "id": "mlBF6-td3yMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creates a function that determines subjectivity and polarity from the textblob package\n",
        "def getTextSubjectivity(clean_text):\n",
        "    return TextBlob(clean_text).sentiment.subjectivity\n",
        "def getTextPolarity(clean_text):\n",
        "    return TextBlob(clean_text).sentiment.polarity\n",
        "#applies these functions to the dataframe\n",
        "df['Subjectivity'] = df['clean_text'].apply(getTextSubjectivity)\n",
        "df['Polarity'] = df['clean_text'].apply(getTextPolarity)\n",
        "#builds a function to calculate and categorize each tweet as Negative, Neutral, and Positive\n",
        "def getTextAnalysis(a):\n",
        "    if a < 0:\n",
        "        return \"Negative\"\n",
        "    elif a == 0:\n",
        "        return \"Neutral\"\n",
        "    else:\n",
        "        return \"Positive\"\n",
        "#creates another column called Score and applies the function to the dataframe\n",
        "df['Score'] = df['Polarity'].apply(getTextAnalysis)"
      ],
      "metadata": {
        "id": "0yweyy2N3wVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizes the data through a bar chart\n",
        "labels = df.groupby('Score').count().index.values\n",
        "values = df.groupby('Score').size().values\n",
        "plt.bar(labels, values, color = ['red', 'blue', 'lime'])\n",
        "plt.title(label = \"Sentiment Analysis\", \n",
        "                  fontsize = '15')\n",
        "#calculates percentage of positive, negative, and neutral tweets\n",
        "positive = df[df['Score'] == 'Positive']\n",
        "print(str(positive.shape[0]/(df.shape[0])*100) + \" % of positive tweets\")\n",
        "positive = df[df['Score'] == 'Neutral']\n",
        "print(str(positive.shape[0]/(df.shape[0])*100) + \" % of neutral tweets\")\n",
        "positive = df[df['Score'] == 'Negative']\n",
        "print(str(positive.shape[0]/(df.shape[0])*100) + \" % of negative tweets\")"
      ],
      "metadata": {
        "id": "RIh40-dm34Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Most trended hashtags\n",
        "top10_hashtags = df.hashtags.str.lower().value_counts().nlargest(10)\n",
        "# initiate the figure with it's size\n",
        "fig = plt.figure(figsize = (10,5))\n",
        "plt.barh(top10_hashtags.index, top10_hashtags.values)\n",
        "plt.xlabel('# of Tweets')\n",
        "plt.title(\"Tweets by hashtags\", fontsize=16);"
      ],
      "metadata": {
        "id": "LopvYQY336ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We are using Compound score to detect the tweet sentiment which is a metric that calculates the sum of\n",
        "# all the lexicon ratings which have been normalized between \n",
        "# -1(most extreme negative) and +1 (most extreme positive)\n",
        "# positive: (compound score >= 0.05), negative : (compound score <= -0.05), neutral otherwise\n",
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "for index, row in tqdm(df.iterrows()): #tqdm \n",
        "    ss = sid.polarity_scores(row['text'])\n",
        "    if ss['compound'] >= 0.05 : \n",
        "        df.at[index,'sentiment'] = \"Positive\"\n",
        "    elif ss['compound'] <= - 0.05 : \n",
        "        df.at[index,'sentiment'] = \"Negative\"\n",
        "    else : \n",
        "        df.at[index,'sentiment'] = \"Neutral\""
      ],
      "metadata": {
        "id": "b0Ia2-TK3-NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tweets sentiments distribution plotted graphically after leaving NLP"
      ],
      "metadata": {
        "id": "P-9Xiyx14AmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show distribution of tweet sentiments\n",
        "sentiment_dist = df.sentiment.value_counts()\n",
        "\n",
        "plt.pie(sentiment_dist, labels=sentiment_dist.index, explode= (0.1,0,0),\n",
        "        colors=['yellowgreen', 'gold', 'lightcoral'],\n",
        "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
        "plt.title(\"Tweets\\' Sentiment Distribution \\n\", fontsize=16, color='Black')\n",
        "plt.axis('equal')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BDXGmmNV3_GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "id": "kdZlHiPU4KZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df=df[['clean_text','Score']]"
      ],
      "metadata": {
        "id": "XhGcOAZ54MaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting our dataset into training and testing dataset (for Multiclass Classification) "
      ],
      "metadata": {
        "id": "x0qZZZvA4Ogq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train,valid = train_test_split(new_df,test_size = 0.2,random_state=0,stratify = new_df.Score.values) #stratification means that the train_test_split method returns training and test subsets that have the same proportions of class labels as the input dataset.\n",
        "print(\"train shape : \", train.shape)\n",
        "print(\"valid shape : \", valid.shape)"
      ],
      "metadata": {
        "id": "ahmVl2uf4YoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Of Counter Vectorizer For Multi Class Classification"
      ],
      "metadata": {
        "id": "zrKNyxe-4a8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "stop = list(stopwords.words('english'))\n",
        "vectorizer = CountVectorizer(decode_error = 'replace',stop_words = stop)\n",
        "\n",
        "X_train = vectorizer.fit_transform(train.clean_text.values)\n",
        "X_valid = vectorizer.transform(valid.clean_text.values)\n",
        "\n",
        "y_train = train.Score.values\n",
        "y_valid = valid.Score.values\n",
        "\n",
        "print(\"X_train.shape : \", X_train.shape)\n",
        "print(\"X_valid.shape : \", X_valid.shape)\n",
        "print(\"y_train.shape : \", y_train.shape)\n",
        "print(\"y_valid.shape : \", y_valid.shape)"
      ],
      "metadata": {
        "id": "TllL-ePO4dHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes Classifier for MULTICLASS Classification"
      ],
      "metadata": {
        "id": "Q_b0-4004foP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "naiveByes_clf = MultinomialNB()\n",
        "\n",
        "naiveByes_clf.fit(X_train,y_train)\n",
        "\n",
        "NB_prediction = naiveByes_clf.predict(X_valid)\n",
        "NB_accuracy = accuracy_score(y_valid,NB_prediction)\n",
        "print(\"training accuracy Score    : \",naiveByes_clf.score(X_train,y_train))\n",
        "print(\"Validation accuracy Score : \",NB_accuracy )\n",
        "print(classification_report(NB_prediction,y_valid))"
      ],
      "metadata": {
        "id": "vNGxd9yb4hlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(NB_prediction,y_valid)\n",
        "matrix_proportions = np.zeros((3,3))\n",
        "for i in range(0,3):\n",
        "    matrix_proportions[i,:] = confusion_matrix[i,:]/float(confusion_matrix[i,:].sum())\n",
        "sents=['Negative','Neutral','Positive']\n",
        "confusion_df = pd.DataFrame(matrix_proportions, index=sents,columns=sents)\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cmap='Blues',cbar=False, square=True,fmt='.2f')\n",
        "plt.ylabel(r'True categories',fontsize=14)\n",
        "plt.xlabel(r'Predicted categories',fontsize=14)\n",
        "plt.tick_params(labelsize=12)"
      ],
      "metadata": {
        "id": "EnQ3Uswd4l3n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}